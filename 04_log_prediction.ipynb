{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04_log_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force to reload extrernal modules every new cell execution\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT ###\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator\n",
    "# DL\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Input, BatchNormalization, Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "# XAI\n",
    "import shap\n",
    "from shap import Explanation\n",
    "# Code warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOCAL IMPORT ###\n",
    "from config import config_reader\n",
    "from utilities import extract_files, convert_seconds_to_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBALS ###\n",
    "yaml_config = config_reader.config_read_yaml(\"config.yml\", \"config\")\n",
    "\n",
    "dic_types = dict(yaml_config[\"EVENT_LOG_TYPES\"]) \n",
    "\n",
    "encoding_dir = str(yaml_config[\"LOG_ENCODING_DIR\"]) # <-- INPUT: the directory with files encoded for the ML models\n",
    "\n",
    "# ML\n",
    "ml_dir = str(yaml_config[\"ML_DIR\"]) # <-- INPUT: the directoryin which to save ML results\n",
    "label_column = \"REMAINING_TIME_sec\" # <-- INPUT: label for prediction\n",
    "drop_column = [\"CaseID\", \"TIMESTAMP\"]  # <-- INPUT: columns to drop\n",
    "cv_folds = int(yaml_config[\"CV_FOLDS\"])\n",
    "\n",
    "dic_task = {\"DTR\":0, \"RFR\":1, \"XGB\":0, \"LSTM\":0} # <-- INPUT: which model to execute\n",
    "\n",
    "ht_do = 0 # <-- INPUT performs hypertuning: 1 yes, 0 no \n",
    "ht_str = None\n",
    "\n",
    "# Event log types (stadard or enriched)\n",
    "std_suffix = str(yaml_config[\"STD_SUFFIX\"])\n",
    "enr_suffix = str(yaml_config[\"ENR_SUFFIX\"])\n",
    "\n",
    "# PLOT\n",
    "plot_dir = str(yaml_config[\"PLOT_DIR\"])\n",
    "\n",
    "# SHAP\n",
    "shap_do = 1 # <-- INPUT performs SHAP: 1 yes, 0 no \n",
    "shap_dir = str(yaml_config[\"SHAP_DIR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_custom_distribution_side_by_side_old(dataframe: pd.DataFrame, x_column: str, y_column: str, encoding_column: str, model_name:str, ht_str:str) -> None:\n",
    "    \"\"\"\n",
    "    This function takes a dataframe as input and displays a side-by-side bar chart of the actual values\n",
    "    for the specified columns, using distinct colours based on the encoding column.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The input dataframe containing the columns to plot.\n",
    "    x_column (str): The name of the column to use for the x-axis.\n",
    "    y_column (str): The name of the column to use for the y-axis.\n",
    "    encoding_column (str): The name of the column that determines the colour encoding.\n",
    "    model_name (str): The name of the model used.\n",
    "    ht_str (str): The model is hypertuned or not.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that the specified columns exist in the dataframe\n",
    "    if x_column not in dataframe.columns or y_column not in dataframe.columns or encoding_column not in dataframe.columns:\n",
    "        raise ValueError(\"The specified columns do not exist in the dataframe.\")\n",
    "    \n",
    "    # Set font properties\n",
    "    plt.rcParams.update({'font.family': 'serif', 'font.serif': 'Times New Roman'})\n",
    "\n",
    "    # Extract unique values\n",
    "    unique_x_values = dataframe[x_column].unique()\n",
    "    unique_encodings = dataframe[encoding_column].unique()\n",
    "    \n",
    "    # Calculate width for each bar\n",
    "    bar_width = 0.25  # Width of each bar\n",
    "    index = np.arange(len(unique_x_values))  # The x locations for the groups\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot bars for each encoding\n",
    "    for i, encoding in enumerate(unique_encodings):\n",
    "        subset = dataframe[dataframe[encoding_column] == encoding]\n",
    "        # Align the bars in each group\n",
    "        plt.bar(index + i * bar_width, subset[y_column], bar_width, label=f'Encoding {encoding}')\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt_title = f\"Distribution of '{y_column}' by '{x_column}' \\n Model: {model_name}\"\n",
    "    plt.title(plt_title)\n",
    "    plt.xlabel(x_column)\n",
    "    plt.ylabel(y_column)\n",
    "    plt.xticks(index + bar_width / 2, unique_x_values, rotation=45)\n",
    "    plt.legend(title=encoding_column)\n",
    "    plt.grid(axis='y')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "\n",
    "    file_path = f'plots/{model_name}_plot_{y_column}_{ht_str}_HT.png'\n",
    "    plt.savefig(file_path)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_custom_distribution_side_by_side(dataframe: pd.DataFrame, x_column: str, y_column: str, encoding_column: str, model_name: str, ht_str: str) -> None:\n",
    "    \"\"\"\n",
    "    This function takes a dataframe as input and displays a side-by-side bar chart of the actual values\n",
    "    for the specified columns, using distinct colours based on the encoding column.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The input dataframe containing the columns to plot.\n",
    "    x_column (str): The name of the column to use for the x-axis.\n",
    "    y_column (str): The name of the column to use for the y-axis.\n",
    "    encoding_column (str): The name of the column that determines the colour encoding.\n",
    "    model_name (str): The name of the model used.\n",
    "    ht_str (str): The model is hypertuned or not.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that the specified columns exist in the dataframe\n",
    "    if x_column not in dataframe.columns or y_column not in dataframe.columns or encoding_column not in dataframe.columns:\n",
    "        raise ValueError(\"The specified columns do not exist in the dataframe.\")\n",
    "\n",
    "    # Set font properties\n",
    "    plt.rcParams.update({'font.family': 'serif', 'font.serif': 'Times New Roman'})\n",
    "\n",
    "    # Extract unique values\n",
    "    unique_x_values = dataframe[x_column].unique()\n",
    "    unique_encodings = dataframe[encoding_column].unique()\n",
    "\n",
    "    # Calculate width for each bar\n",
    "    bar_width = 0.25  # Width of each bar\n",
    "    index = np.arange(len(unique_x_values))  # The x locations for the groups\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot bars for each encoding\n",
    "    for i, encoding in enumerate(unique_encodings):\n",
    "        subset = dataframe[dataframe[encoding_column] == encoding]\n",
    "        # Align the bars in each group\n",
    "        bars = plt.bar(index + i * bar_width, subset[y_column], bar_width, label=f'Encoding {encoding}')\n",
    "\n",
    "        # Add data labels on top of each bar\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom', color='black', fontsize=9)\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt_title = f\"Distribution of '{y_column}' by '{x_column}' \\n Model: {model_name}\"\n",
    "    plt.title(plt_title)\n",
    "    plt.xlabel(x_column)\n",
    "    plt.ylabel(y_column)\n",
    "    plt.xticks(index + bar_width / 2 * len(unique_encodings), unique_x_values, rotation=45)\n",
    "    plt.legend(title=encoding_column)\n",
    "    plt.grid(axis='y')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "\n",
    "    file_path = f'plots/{model_name}_plot_{y_column}_{ht_str}_HT.png'\n",
    "    plt.savefig(file_path)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_regression_lstm_base(X_train: pd.DataFrame,y_train: pd.Series, X_test: pd.DataFrame,y_test: pd.Series, target: pd.Series, df_log_ml_features: pd.DataFrame, file_name: str, type: str,prefix: str, encoding: str,cv_folds: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Perform regression using LSTM and evaluate the model with RMSE and MAE.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target variable.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        y_test (pd.Series): Test target variable.\n",
    "        target (pd.Series): Target variable for cross-validation.\n",
    "        df_log_ml_features (pd.DataFrame): Complete features for cross-validation.\n",
    "        file_name (str): Name of the file.\n",
    "        type (str): Type of the file (std or enr).\n",
    "        prefix (str): Prefix for the model.\n",
    "        encoding (str): Encoding type.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics.\n",
    "    \"\"\"\n",
    "    print(\">> Performing LSTM Regression\")\n",
    "\n",
    "    # Reshape for LSTM [samples, time steps, features]\n",
    "    n_features = X_train.shape[1]\n",
    "    print(\"n_features:\", n_features) # debug\n",
    "    X_train_reshaped = X_train.values.reshape((X_train.shape[0], 1, n_features))\n",
    "    X_test_reshaped = X_test.values.reshape((X_test.shape[0], 1, n_features))\n",
    "    print(\"X train reshape:\", X_train_reshaped.shape) # debug\n",
    "    print(\"X train reshape:\", X_test_reshaped.shape) # debug\n",
    "\n",
    "    # LSTM model \n",
    "    dropout_rate = 0.3\n",
    "    units_num = 300\n",
    "    reg_strength = 0.01\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # First level\n",
    "    model.add(Input(shape=(1, n_features)))\n",
    "    model.add(Bidirectional(LSTM(units=units_num, activation='relu', kernel_regularizer=l2(reg_strength), return_sequences=True)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Second level  \n",
    "    model.add(Bidirectional(LSTM(units=units_num, activation='relu', kernel_regularizer=l2(reg_strength), return_sequences=True)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Third level\n",
    "    model.add(Bidirectional(LSTM(units=units_num, activation='relu', kernel_regularizer=l2(reg_strength)))) # return_sequences=True *not* needed in the last layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Model compilation\n",
    "    # model.compile(optimizer='rmsprop', loss='mse')\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "    # print(model.summary()) # debug\n",
    "    \n",
    "    # Utilizzo di early stopping per prevenire l'overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Addestramento del modello\n",
    "    model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "    # Predizione sui dati di test\n",
    "    y_pred = model.predict(X_test_reshaped)\n",
    "\n",
    "    # Valutazione\n",
    "    # RMSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(\"RMSE of the model in seconds before CV:\", rmse)\n",
    "    print(\"MAE of the model in seconds before CV:\", mae)\n",
    "\n",
    "    print(\"> CV validation\")\n",
    "    print(\"Folds:\", cv_folds)\n",
    "\n",
    "    # Prepare reshaped features for cross-validation\n",
    "    def lstm_cross_val_predictor(X, y, cv_folds, n_features):\n",
    "        \"\"\" Cross-validation utility for LSTM.\"\"\"\n",
    "        scores_rmse = []\n",
    "        scores_mae = []\n",
    "        kfold = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "            y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "            # Reshape folds for LSTM input\n",
    "            X_train_fold = X_train_fold.reshape((X_train_fold.shape[0], 1, n_features))\n",
    "            X_test_fold = X_test_fold.reshape((X_test_fold.shape[0], 1, n_features))\n",
    "\n",
    "            # Define model\n",
    "            dropout_rate = 0.3\n",
    "            units_num = 400\n",
    "            reg_strength = 0.01\n",
    "\n",
    "            model_fold = Sequential()\n",
    "\n",
    "            # First level\n",
    "            model_fold.add(Input(shape=(1, n_features)))\n",
    "            model_fold.add(Bidirectional(LSTM(units=units_num, activation='relu', kernel_regularizer=l2(reg_strength), return_sequences=True)))\n",
    "            model_fold.add(Dropout(dropout_rate))\n",
    "            model_fold.add(BatchNormalization())\n",
    "\n",
    "            # Second level  \n",
    "            model_fold.add(Bidirectional(LSTM(units=units_num, activation='relu', kernel_regularizer=l2(reg_strength), return_sequences=True)))\n",
    "            model_fold.add(Dropout(dropout_rate))\n",
    "            model_fold.add(BatchNormalization())\n",
    "\n",
    "            # Third level\n",
    "            model_fold.add(Bidirectional(LSTM(units=units_num, activation='relu', kernel_regularizer=l2(reg_strength)))) # return_sequences=True *not* needed in the last layer\n",
    "            model_fold.add(Dropout(dropout_rate))\n",
    "            model_fold.add(BatchNormalization())\n",
    "\n",
    "            # Output layer\n",
    "            model_fold.add(Dense(1))\n",
    "\n",
    "            # Model compilation\n",
    "            # model.compile(optimizer='rmsprop', loss='mse')\n",
    "            model_fold.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "            # Train model\n",
    "            early_stopping_fold = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "            model_fold.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0, callbacks=[early_stopping_fold])\n",
    "\n",
    "            # Evaluate model\n",
    "            y_pred_fold = model_fold.predict(X_test_fold)\n",
    "            rmse_fold = np.sqrt(mean_squared_error(y_test_fold, y_pred_fold))\n",
    "            mae_fold = mean_absolute_error(y_test_fold, y_pred_fold)\n",
    "\n",
    "            scores_rmse.append(rmse_fold)\n",
    "            scores_mae.append(mae_fold)\n",
    "\n",
    "        return np.array(scores_rmse), np.array(scores_mae)\n",
    "\n",
    "    # Prepare data for cross-validation\n",
    "    X_cv = df_log_ml_features.values\n",
    "    y_cv = target.values\n",
    "\n",
    "    # Reshape features for LSTM input\n",
    "    X_cv = X_cv.reshape((X_cv.shape[0], 1, n_features))\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cv_rmse_scores, cv_mae_scores = lstm_cross_val_predictor(X_cv, y_cv, cv_folds, n_features)\n",
    "\n",
    "    cv_rmse_mean = cv_rmse_scores.mean()\n",
    "    cv_rmse_std = cv_rmse_scores.std()\n",
    "\n",
    "    cv_mae_mean = cv_mae_scores.mean()\n",
    "    cv_mae_std = cv_mae_scores.std()\n",
    "\n",
    "    # Convert all (MAE and RMSE) seconds to minutes and hours\n",
    "    cv_rmse_mean_m, cv_rmse_mean_h = convert_seconds_to_hours(cv_rmse_mean)\n",
    "    cv_rmse_std_m, cv_rmse_std_h = convert_seconds_to_hours(cv_rmse_std)\n",
    "    cv_mae_mean_m, cv_mae_mean_h = convert_seconds_to_hours(cv_mae_mean)\n",
    "    cv_mae_std_m, cv_mae_std_h = convert_seconds_to_hours(cv_mae_std)\n",
    "\n",
    "    print(f\"RMSE of every fold in seconds: {cv_rmse_scores} \\n RMSE mean: {cv_rmse_mean:.2f}, RMSE std: {cv_rmse_std:.2f}\")\n",
    "    print(f\"MAE of every fold in seconds: {cv_mae_scores} \\n MAE mean: {cv_mae_mean:.2f}, MAE std: {cv_mae_std:.2f}\")\n",
    "    print(f\"Cross-validated RMSE mean: {cv_rmse_mean_m:.2f} minutes, {cv_rmse_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated RMSE std: {cv_rmse_std_m:.2f} minutes, {cv_rmse_std_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE mean: {cv_mae_mean_m:.2f} minutes, {cv_mae_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE std: {cv_mae_std_m:.2f} minutes, {cv_mae_std_h:.2f} hours\")\n",
    "    print()\n",
    "    \n",
    "    results_dict = {\n",
    "        \"Model\": \"LSTM\",\n",
    "        \"File\": file_name,\n",
    "        \"Type\": type,\n",
    "        \"Prefix (h)\": prefix,\n",
    "        \"Encoding\": encoding,\n",
    "        \"RMSE_Before_CV_s\": rmse,\n",
    "        \"MAE_Before_CV_s\": mae,\n",
    "        \"RMSE_CV_scores_s\": cv_rmse_scores.tolist(),\n",
    "        \"RMSE_CV_Mean_s\": cv_rmse_mean,\n",
    "        \"RMSE_CV_Std_s\": cv_rmse_std,\n",
    "        \"RMSE_CV_Mean_m\": cv_rmse_mean_m,\n",
    "        \"RMSE_CV_Std_m\": cv_rmse_std_m,\n",
    "        \"MAE_CV_Scores_s\": cv_mae_scores.tolist(),\n",
    "        \"MAE_CV_Mean_s\": cv_mae_mean,\n",
    "        \"MAE_CV_Std_s\": cv_mae_std,\n",
    "        \"MAE_CV_Mean_m\": cv_mae_mean_m,\n",
    "        \"MAE_CV_Std_m\": cv_mae_std_m\n",
    "    }\n",
    "\n",
    "    return results_dict, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_regression_dtr_base(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, target: pd.Series, df_log_ml_features: pd.DataFrame, file_name:str, type:str, prefix:str, encoding:str, cv_folds: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Perform regression using Decision Tree and evaluate the model with RMSE.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target variable.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        y_test (pd.Series): Test target variable.\n",
    "        target (pd.Series): Target variable for cross-validation.\n",
    "        df_log_ml_features (pd.DataFrame): Complete features for cross-validation.\n",
    "        file_name (str): Name of the file.\n",
    "        type (str): Type of the file (std or enr).\n",
    "        prefix (str): Prefix for the model.\n",
    "        encoding (str): Encoding type.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics.\n",
    "    \"\"\"\n",
    "    print(\">> Performing DTR\")\n",
    "    # Training\n",
    "    dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "    dt_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Test the training\n",
    "    y_pred = dt_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    # RMSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(\"RMSE of the model in second before CV:\", rmse)\n",
    "    print(\"MAE of the model in seconds before CV:\", mae)\n",
    "\n",
    "    print(\"> CV validation\")\n",
    "    print(\"Folds:\", cv_folds)\n",
    "\n",
    "    # RMSE Cross-validation with best model\n",
    "    neg_rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "    cv_rmse_scores = cross_val_score(dt_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_rmse_scorer)\n",
    "\n",
    "    # Convert negative RMSE scores to positive values\n",
    "    cv_rmse_scores = -cv_rmse_scores\n",
    "    cv_rmse_mean = cv_rmse_scores.mean()\n",
    "    cv_rmse_std = cv_rmse_scores.std()\n",
    "\n",
    "    # MAE Cross-validation with best model\n",
    "    neg_mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    cv_mae_scores = cross_val_score(dt_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_mae_scorer)\n",
    "\n",
    "    # Convert negative MAE scores to positive values\n",
    "    cv_mae_scores = -cv_mae_scores\n",
    "    cv_mae_mean = cv_mae_scores.mean()\n",
    "    cv_mae_std = cv_mae_scores.std()\n",
    "\n",
    "    # Convert all (MAE and RMSE) seconds to minutes and hours \n",
    "    cv_rmse_mean_m, cv_rmse_mean_h = convert_seconds_to_hours(cv_rmse_mean)\n",
    "    cv_rmse_std_m, cv_rmse_std_h = convert_seconds_to_hours(cv_rmse_std)\n",
    "    cv_mae_mean_m, cv_mae_mean_h = convert_seconds_to_hours(cv_mae_mean)\n",
    "    cv_mae_std_m, cv_mae_std_h = convert_seconds_to_hours(cv_mae_std)\n",
    "\n",
    "    print(f\"RMSE of every fold in seconds: {cv_rmse_scores} \\n RMSE mean: {cv_rmse_mean:.2f}, RMSE std: {cv_rmse_std:.2f}\")\n",
    "    print(f\"MAE of every fold in seconds: {cv_mae_scores} \\n MAE mean: {cv_mae_mean:.2f}, MAE std: {cv_mae_std:.2f}\")\n",
    "    print(f\"Cross-validated RMSE mean: {cv_rmse_mean_m:.2f} minutes, {cv_rmse_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated RMSE std: {cv_rmse_std_m:.2f} minutes, {cv_rmse_std_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE mean: {cv_mae_mean_m:.2f} minutes, {cv_mae_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE std: {cv_mae_std_m:.2f} minutes, {cv_mae_std_h:.2f} hours\")\n",
    "    print()\n",
    "\n",
    "    results_dict = {\n",
    "        \"Model\": \"DTR\",\n",
    "        \"File\": file_name,\n",
    "        \"Type\": type,\n",
    "        \"Prefix (h)\": prefix,\n",
    "        \"Encoding\": encoding,\n",
    "        \"RMSE_Before_CV_s\": rmse,\n",
    "        \"MAE_Before_CV_s\": mae,\n",
    "        \"RMSE_CV_scores_s\": cv_rmse_scores.tolist(),\n",
    "        \"RMSE_CV_Mean_s\": cv_rmse_mean,\n",
    "        \"RMSE_CV_Std_s\": cv_rmse_std,\n",
    "        \"RMSE_CV_Mean_m\": cv_rmse_mean_m,\n",
    "        \"RMSE_CV_Std_m\": cv_rmse_std_m,\n",
    "        \"MAE_CV_Scores_s\": cv_mae_scores.tolist(),\n",
    "        \"MAE_CV_Mean_s\": cv_mae_mean,\n",
    "        \"MAE_CV_Std_s\": cv_mae_std,\n",
    "        \"MAE_CV_Mean_m\": cv_mae_mean_m,\n",
    "        \"MAE_CV_Std_m\": cv_mae_std_m\n",
    "    }\n",
    "\n",
    "    return results_dict, dt_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_regression_rfr_base(X_train: pd.DataFrame, y_train: pd.Series, X_test:pd.DataFrame, y_test: pd.Series, target: pd.Series, df_log_ml_features: pd.DataFrame, file_name:str, type:str, prefix:str, encoding:str, cv_folds: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Perform regression using Random Forest and evaluate the model with RMSE.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target variable.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        y_test (pd.Series): Test target variable.\n",
    "        target (pd.Series): Target variable for cross-validation.\n",
    "        df_log_ml_features (pd.DataFrame): Complete features for cross-validation.\n",
    "        file_name (str): Name of the file.\n",
    "        type (str): Type of the file (std or enr).\n",
    "        prefix (str): Prefix for the model.\n",
    "        encoding (str): Encoding type.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics.\n",
    "    \"\"\"\n",
    "    print(\">> Performing RFR\")\n",
    "    # Training\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Test the training\n",
    "    y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    # RMSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(\"RMSE of the model in second before CV:\", rmse)\n",
    "    print(\"MAE of the model in seconds before CV:\", mae)\n",
    "\n",
    "    print(\"> CV validation\")\n",
    "    print(\"Folds:\", cv_folds)\n",
    "\n",
    "    # RMSE Cross-validation with best model\n",
    "    neg_rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "    cv_rmse_scores = cross_val_score(rf_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_rmse_scorer)\n",
    "\n",
    "    # Convert negative RMSE scores to positive values\n",
    "    cv_rmse_scores = -cv_rmse_scores\n",
    "    cv_rmse_mean = cv_rmse_scores.mean()\n",
    "    cv_rmse_std = cv_rmse_scores.std()\n",
    "\n",
    "    # MAE Cross-validation with best model\n",
    "    neg_mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    cv_mae_scores = cross_val_score(rf_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_mae_scorer)\n",
    "\n",
    "    # MAE Cross-validation\n",
    "    cv_mae_scores = cross_val_score(rf_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_mae_scorer)\n",
    "\n",
    "    # Convert negative MAE scores to positive values\n",
    "    cv_mae_scores = -cv_mae_scores\n",
    "    cv_mae_mean = cv_mae_scores.mean()\n",
    "    cv_mae_std = cv_mae_scores.std()\n",
    "\n",
    "    # Convert all (MAE and RMSE) seconds to minutes and hours \n",
    "    cv_rmse_mean_m, cv_rmse_mean_h = convert_seconds_to_hours(cv_rmse_mean)\n",
    "    cv_rmse_std_m, cv_rmse_std_h = convert_seconds_to_hours(cv_rmse_std)\n",
    "    cv_mae_mean_m, cv_mae_mean_h = convert_seconds_to_hours(cv_mae_mean)\n",
    "    cv_mae_std_m, cv_mae_std_h = convert_seconds_to_hours(cv_mae_std)\n",
    "\n",
    "    print(f\"RMSE of every fold in seconds: {cv_rmse_scores} \\n RMSE mean: {cv_rmse_mean:.2f}, RMSE std: {cv_rmse_std:.2f}\")\n",
    "    print(f\"MAE of every fold in seconds: {cv_mae_scores} \\n MAE mean: {cv_mae_mean}:.2f, RMSE std: {cv_mae_std:.2f}\")\n",
    "    print(f\"Cross-validated RMSE mean: {cv_rmse_mean_m:.2f} minutes, {cv_rmse_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated RMSE std: {cv_rmse_std_m:.2f} minutes, {cv_rmse_std_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE mean: {cv_mae_mean_m:.2f} minutes, {cv_mae_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE std: {cv_mae_std_m:.2f} minutes, {cv_mae_std_h:.2f} hours\")\n",
    "    print()\n",
    "    \n",
    "    results_dict = {\n",
    "    \"Model\": \"RFR\",\n",
    "        \"File\": file_name,\n",
    "        \"Type\": type,\n",
    "        \"Prefix (h)\": prefix,\n",
    "        \"Encoding\": encoding,\n",
    "        \"RMSE_Before_CV_s\": rmse,\n",
    "        \"MAE_Before_CV_s\": mae,\n",
    "        \"RMSE_CV_scores_s\": cv_rmse_scores.tolist(),\n",
    "        \"RMSE_CV_Mean_s\": cv_rmse_mean,\n",
    "        \"RMSE_CV_Std_s\": cv_rmse_std,\n",
    "        \"RMSE_CV_Mean_m\": cv_rmse_mean_m,\n",
    "        \"RMSE_CV_Std_m\": cv_rmse_std_m,\n",
    "        \"MAE_CV_Scores_s\": cv_mae_scores.tolist(),\n",
    "        \"MAE_CV_Mean_s\": cv_mae_mean,\n",
    "        \"MAE_CV_Std_s\": cv_mae_std,\n",
    "        \"MAE_CV_Mean_m\": cv_mae_mean_m,\n",
    "        \"MAE_CV_Std_m\": cv_mae_std_m\n",
    "    }\n",
    "\n",
    "    return results_dict, rf_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_regression_xgr_base(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, target: pd.Series, df_log_ml_features: pd.DataFrame, file_name: str, type:str, prefix: str, encoding: str, cv_folds: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Perform regression using XGBoost and evaluate the model with RMSE.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target variable.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        y_test (pd.Series): Test target variable.\n",
    "        target (pd.Series): Target variable for cross-validation.\n",
    "        df_log_ml_features (pd.DataFrame): Complete features for cross-validation.\n",
    "        file_name (str): Name of the file.\n",
    "        type (str): Type of the file (std or enr).\n",
    "        prefix (str): Prefix for the model.\n",
    "        encoding (str): Encoding type.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics.\n",
    "    \"\"\"\n",
    "    print(\">> Performing XGBoost Regression\")\n",
    "\n",
    "    # Training the model\n",
    "    xgb_regressor = XGBRegressor(n_estimators=150, random_state=42, verbosity=0)\n",
    "    xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Test the training\n",
    "    y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    # RMSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(\"RMSE of the model in second before CV:\", rmse)\n",
    "    print(\"MAE of the model in seconds CV:\", mae)\n",
    "\n",
    "    print(\"> CV validation\")\n",
    "    print(\"Folds:\", cv_folds)\n",
    "\n",
    "    # RMSE Cross-validation with best model\n",
    "    neg_rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "    cv_rmse_scores = cross_val_score(xgb_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_rmse_scorer)\n",
    "\n",
    "    # Convert negative RMSE scores to positive values\n",
    "    cv_rmse_scores = -cv_rmse_scores\n",
    "    cv_rmse_mean = cv_rmse_scores.mean()\n",
    "    cv_rmse_std = cv_rmse_scores.std()\n",
    "\n",
    "    # MAE Cross-validation with best model\n",
    "    neg_mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    cv_mae_scores = cross_val_score(xgb_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_mae_scorer)\n",
    "\n",
    "    # MAE Cross-validation\n",
    "    cv_mae_scores = cross_val_score(xgb_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_mae_scorer)\n",
    "\n",
    "    # Convert negative MAE scores to positive values\n",
    "    cv_mae_scores = -cv_mae_scores\n",
    "    cv_mae_mean = cv_mae_scores.mean()\n",
    "    cv_mae_std = cv_mae_scores.std()\n",
    "\n",
    "    # Convert all (MAE and RMSE) seconds to minutes and hours \n",
    "    cv_rmse_mean_m, cv_rmse_mean_h = convert_seconds_to_hours(cv_rmse_mean)\n",
    "    cv_rmse_std_m, cv_rmse_std_h = convert_seconds_to_hours(cv_rmse_std)\n",
    "    cv_mae_mean_m, cv_mae_mean_h = convert_seconds_to_hours(cv_mae_mean)\n",
    "    cv_mae_std_m, cv_mae_std_h = convert_seconds_to_hours(cv_mae_std)\n",
    "\n",
    "    print(f\"RMSE of every fold in seconds: {cv_rmse_scores} \\n RMSE mean: {cv_rmse_mean:.2f}, RMSE std: {cv_rmse_std:.2f}\")\n",
    "    print(f\"MAE of every fold in seconds: {cv_mae_scores} \\n MAE mean: {cv_mae_mean}:.2f, RMSE std: {cv_mae_std:.2f}\")\n",
    "    print(f\"Cross-validated RMSE mean: {cv_rmse_mean_m:.2f} minutes, {cv_rmse_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated RMSE std: {cv_rmse_std_m:.2f} minutes, {cv_rmse_std_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE mean: {cv_mae_mean_m:.2f} minutes, {cv_mae_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE std: {cv_mae_std_m:.2f} minutes, {cv_mae_std_h:.2f} hours\")\n",
    "    print()\n",
    "    \n",
    "    results_dict = {\n",
    "        \"Model\": \"XGR\",\n",
    "        \"File\": file_name,\n",
    "        \"Type\": type,\n",
    "        \"Prefix (h)\": prefix,\n",
    "        \"Encoding\": encoding,\n",
    "        \"RMSE_Before_CV_s\": rmse,\n",
    "        \"MAE_Before_CV_s\": mae,\n",
    "        \"RMSE_CV_scores_s\": cv_rmse_scores.tolist(),\n",
    "        \"RMSE_CV_Mean_s\": cv_rmse_mean,\n",
    "        \"RMSE_CV_Std_s\": cv_rmse_std,\n",
    "        \"RMSE_CV_Mean_m\": cv_rmse_mean_m,\n",
    "        \"RMSE_CV_Std_m\": cv_rmse_std_m,\n",
    "        \"MAE_CV_Scores_s\": cv_mae_scores.tolist(),\n",
    "        \"MAE_CV_Mean_s\": cv_mae_mean,\n",
    "        \"MAE_CV_Std_s\": cv_mae_std,\n",
    "        \"MAE_CV_Mean_m\": cv_mae_mean_m,\n",
    "        \"MAE_CV_Std_m\": cv_mae_std_m\n",
    "    }\n",
    "\n",
    "    return results_dict, xgb_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_regression_rfr(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, target: pd.Series, df_log_ml_features: pd.DataFrame, file_name: str, type:str, prefix: str, encoding: str, cv_folds: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Perform regression using Random Forest with hyperparameter optimization using Hyperopt.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target variable.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        y_test (pd.Series): Test target variable.\n",
    "        target (pd.Series): Target variable for cross-validation.\n",
    "        df_log_ml_features (pd.DataFrame): Complete features for cross-validation.\n",
    "        file_name (str): Name of the file.\n",
    "        type (str): Type of the file (std or enr).\n",
    "        prefix (str): Prefix for the model.\n",
    "        encoding (str): Encoding type.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics and best hyperparameters.\n",
    "    \"\"\"\n",
    "    print(\">> Performing RFR\")\n",
    "    \n",
    "    def objective(params):\n",
    "        \n",
    "        rf_regressor = RandomForestRegressor(\n",
    "            n_estimators=int(params['n_estimators']),\n",
    "            max_depth=params['max_depth'],\n",
    "            min_samples_split=int(params['min_samples_split']),\n",
    "            min_samples_leaf=int(params['min_samples_leaf']),\n",
    "            max_features=params.get('max_features', 'auto'),\n",
    "            bootstrap=params.get('bootstrap', True),\n",
    "            oob_score=params.get('oob_score', False),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scorer define for RMSE (negative since cross_val_score minimizes the score)\n",
    "        neg_rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "\n",
    "        # Cross-validation to get the negative RMSE\n",
    "        cv_scores = cross_val_score(rf_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_rmse_scorer)\n",
    "        \n",
    "        # Convert the negative scores to positive for RMSE\n",
    "        cv_rmse_scores = -cv_scores\n",
    "        cv_rmse_mean = cv_rmse_scores.mean()\n",
    "        \n",
    "        return {'loss': cv_rmse_mean, 'status': STATUS_OK}\n",
    "\n",
    "    # Define the hyperparameter space\n",
    "    param_space = {\n",
    "            'n_estimators': [int(x) for x in range(10, 501, 50)],  \n",
    "            'max_depth': [int(x) for x in range(5, 51, 5)] + [None], \n",
    "            'min_samples_split': [2, 5, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4, 10],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'bootstrap': [True, False],\n",
    "            'oob_score': [True, False]\n",
    "        }\n",
    "\n",
    "    # Run the optimization\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=objective, space=param_space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "\n",
    "    print(\"Best hyperparameters found: \", best)\n",
    "\n",
    "    # Train the model with the best hyperparameters\n",
    "    rf_regressor = RandomForestRegressor(\n",
    "        n_estimators=int(best['n_estimators']),\n",
    "        max_depth=int(best['max_depth']),\n",
    "        min_samples_split=int(best['min_samples_split']),\n",
    "        min_samples_leaf=int(best['min_samples_leaf']),\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Test the training\n",
    "    y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    # RMSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(\"RMSE of the model in second before CV:\", rmse)\n",
    "    print(\"MAE of the model in seconds before CV:\", mae)\n",
    "\n",
    "    print(\"> CV validation\")\n",
    "    print(\"Folds:\", cv_folds)\n",
    "\n",
    "    # RMSE Cross-validation with best model\n",
    "    neg_rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "    cv_rmse_scores = cross_val_score(rf_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_rmse_scorer)\n",
    "\n",
    "    # Convert negative RMSE scores to positive values\n",
    "    cv_rmse_scores = -cv_rmse_scores\n",
    "    cv_rmse_mean = cv_rmse_scores.mean()\n",
    "    cv_rmse_std = cv_rmse_scores.std()\n",
    "\n",
    "    # MAE Cross-validation with best model\n",
    "    neg_mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    cv_mae_scores = cross_val_score(rf_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_mae_scorer)\n",
    "\n",
    "    # MAE Cross-validation\n",
    "    cv_mae_scores = cross_val_score(rf_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_mae_scorer)\n",
    "\n",
    "    # Convert negative MAE scores to positive values\n",
    "    cv_mae_scores = -cv_mae_scores\n",
    "    cv_mae_mean = cv_mae_scores.mean()\n",
    "    cv_mae_std = cv_mae_scores.std()\n",
    "\n",
    "    # Convert all (MAE and RMSE) seconds to minutes and hours \n",
    "    cv_rmse_mean_m, cv_rmse_mean_h = convert_seconds_to_hours(cv_rmse_mean)\n",
    "    cv_rmse_std_m, cv_rmse_std_h = convert_seconds_to_hours(cv_rmse_std)\n",
    "    cv_mae_mean_m, cv_mae_mean_h = convert_seconds_to_hours(cv_mae_mean)\n",
    "    cv_mae_std_m, cv_mae_std_h = convert_seconds_to_hours(cv_mae_std)\n",
    "\n",
    "    print(f\"RMSE of every fold in seconds: {cv_rmse_scores} \\n RMSE mean: {cv_rmse_mean:.2f}, RMSE std: {cv_rmse_std:.2f}\")\n",
    "    print(f\"MAE of every fold in seconds: {cv_mae_scores} \\n MAE mean: {cv_mae_mean}:.2f, RMSE std: {cv_mae_std:.2f}\")\n",
    "    print(f\"Cross-validated RMSE mean: {cv_rmse_mean_m:.2f} minutes, {cv_rmse_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated RMSE std: {cv_rmse_std_m:.2f} minutes, {cv_rmse_std_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE mean: {cv_mae_mean_m:.2f} minutes, {cv_mae_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE std: {cv_mae_std_m:.2f} minutes, {cv_mae_std_h:.2f} hours\")\n",
    "    print()\n",
    "    \n",
    "    results_dict = {\n",
    "        \"Model\": \"RFR\",\n",
    "        \"File\": file_name,\n",
    "        \"Type\": type,\n",
    "        \"Prefix (h)\": prefix,\n",
    "        \"Encoding\": encoding,\n",
    "        \"RMSE_Before_CV_s\": rmse,\n",
    "        \"MAE_Before_CV_s\": mae,\n",
    "        \"RMSE_CV_scores_s\": cv_rmse_scores.tolist(),\n",
    "        \"RMSE_CV_Mean_s\": cv_rmse_mean,\n",
    "        \"RMSE_CV_Std_s\": cv_rmse_std,\n",
    "        \"RMSE_CV_Mean_m\": cv_rmse_mean_m,\n",
    "        \"RMSE_CV_Std_m\": cv_rmse_std_m,\n",
    "        \"MAE_CV_Scores_s\": cv_mae_scores.tolist(),\n",
    "        \"MAE_CV_Mean_s\": cv_mae_mean,\n",
    "        \"MAE_CV_Std_s\": cv_mae_std,\n",
    "        \"MAE_CV_Mean_m\": cv_mae_mean_m,\n",
    "        \"MAE_CV_Std_m\": cv_mae_std_m,\n",
    "        \"Best_Hyperparameters\": best  # Added best hyperparameters\n",
    "    }\n",
    "\n",
    "    return results_dict, rf_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPEROPT\n",
    "def perform_regression_xgr(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, target: pd.Series, df_log_ml_features: pd.DataFrame, file_name: str, type:str, prefix: str, encoding: str, cv_folds: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Perform regression using XGBoost with hyperparameter optimization and evaluate the model with RMSE.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target variable.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        y_test (pd.Series): Test target variable.\n",
    "        target (pd.Series): Target variable for cross-validation.\n",
    "        df_log_ml_features (pd.DataFrame): Complete features for cross-validation.\n",
    "        file_name (str): Name of the file.\n",
    "        type (str): Type of the file (std or enr).\n",
    "        prefix (str): Prefix for the model.\n",
    "        encoding (str): Encoding type.\n",
    "        cv_folds (int): Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the evaluation metrics.\n",
    "    \"\"\"\n",
    "    print(\">> Performing XGBoost Regression with Hyperopt\")\n",
    "\n",
    "    # Objective function for Hyperopt\n",
    "    def objective(params):\n",
    "        model = XGBRegressor(\n",
    "            max_depth=int(params['max_depth']),\n",
    "            learning_rate=params['learning_rate'],\n",
    "            subsample=params['subsample'],\n",
    "            colsample_bytree=params['colsample_bytree'],\n",
    "            n_estimators=params['n_estimators'],\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        )\n",
    "        # Using cross-validation to evaluate the model\n",
    "        neg_rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "        cv_scores = cross_val_score(model, df_log_ml_features, target, cv=cv_folds, scoring=neg_rmse_scorer)\n",
    "        return -cv_scores.mean()  # Minimize negative RMSE\n",
    "\n",
    "    # Define the hyperparameter space\n",
    "    param_space = {\n",
    "    'max_depth': hp.quniform('max_depth', 3, 15, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "    'n_estimators': hp.choice('n_estimators', [100, 150, 200, 250, 300]),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'gamma': hp.uniform('gamma', 0, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 1)\n",
    "    }\n",
    "    \n",
    "    # Optimize hyperparameters\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=objective, space=param_space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "\n",
    "    print(\"Best hyperparameters:\", best)\n",
    "\n",
    "    # Train the final model with best hyperparameters\n",
    "    xgb_regressor = XGBRegressor(\n",
    "        max_depth=int(best['max_depth']),\n",
    "        learning_rate=best['learning_rate'],\n",
    "        subsample=best['subsample'],\n",
    "        colsample_bytree=best['colsample_bytree'],\n",
    "        n_estimators=best['n_estimators'],\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Test the model\n",
    "    y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    # RMSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(\"RMSE of the model in second before CV:\", rmse)\n",
    "    print(\"MAE of the model in seconds CV:\", mae)\n",
    "\n",
    "    print(\"> CV validation\")\n",
    "    print(\"Folds:\", cv_folds)\n",
    "\n",
    "    # RMSE Cross-validation with best model\n",
    "    neg_rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "    cv_rmse_scores = cross_val_score(xgb_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_rmse_scorer)\n",
    "\n",
    "    # Convert negative RMSE scores to positive values\n",
    "    cv_rmse_scores = -cv_rmse_scores\n",
    "    cv_rmse_mean = cv_rmse_scores.mean()\n",
    "    cv_rmse_std = cv_rmse_scores.std()\n",
    "\n",
    "    # MAE Cross-validation with best model\n",
    "    neg_mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    cv_mae_scores = cross_val_score(xgb_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_mae_scorer)\n",
    "\n",
    "    # MAE Cross-validation\n",
    "    cv_mae_scores = cross_val_score(xgb_regressor, df_log_ml_features, target, cv=cv_folds, scoring=neg_mae_scorer)\n",
    "\n",
    "    # Convert negative MAE scores to positive values\n",
    "    cv_mae_scores = -cv_mae_scores\n",
    "    cv_mae_mean = cv_mae_scores.mean()\n",
    "    cv_mae_std = cv_mae_scores.std()\n",
    "\n",
    "    # Convert all (MAE and RMSE) seconds to minutes and hours \n",
    "    cv_rmse_mean_m, cv_rmse_mean_h = convert_seconds_to_hours(cv_rmse_mean)\n",
    "    cv_rmse_std_m, cv_rmse_std_h = convert_seconds_to_hours(cv_rmse_std)\n",
    "    cv_mae_mean_m, cv_mae_mean_h = convert_seconds_to_hours(cv_mae_mean)\n",
    "    cv_mae_std_m, cv_mae_std_h = convert_seconds_to_hours(cv_mae_std)\n",
    "\n",
    "    print(f\"RMSE of every fold in seconds: {cv_rmse_scores} \\n RMSE mean: {cv_rmse_mean:.2f}, RMSE std: {cv_rmse_std:.2f}\")\n",
    "    print(f\"MAE of every fold in seconds: {cv_mae_scores} \\n MAE mean: {cv_mae_mean}:.2f, RMSE std: {cv_mae_std:.2f}\")\n",
    "    print(f\"Cross-validated RMSE mean: {cv_rmse_mean_m:.2f} minutes, {cv_rmse_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated RMSE std: {cv_rmse_std_m:.2f} minutes, {cv_rmse_std_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE mean: {cv_mae_mean_m:.2f} minutes, {cv_mae_mean_h:.2f} hours\")\n",
    "    print(f\"Cross-validated MAE std: {cv_mae_std_m:.2f} minutes, {cv_mae_std_h:.2f} hours\")\n",
    "    print()\n",
    "\n",
    "    results_dict = {\n",
    "        \"Model\": \"XGR\",\n",
    "        \"File\": file_name,\n",
    "        \"Type\": type,\n",
    "        \"Prefix (h)\": prefix,\n",
    "        \"Encoding\": encoding,\n",
    "        \"RMSE_Before_CV_s\": rmse,\n",
    "        \"MAE_Before_CV_s\": mae,\n",
    "        \"RMSE_CV_scores_s\": cv_rmse_scores.tolist(),\n",
    "        \"RMSE_CV_Mean_s\": cv_rmse_mean,\n",
    "        \"RMSE_CV_Std_s\": cv_rmse_std,\n",
    "        \"RMSE_CV_Mean_m\": cv_rmse_mean_m,\n",
    "        \"RMSE_CV_Std_m\": cv_rmse_std_m,\n",
    "        \"MAE_CV_Scores_s\": cv_mae_scores.tolist(),\n",
    "        \"MAE_CV_Mean_s\": cv_mae_mean,\n",
    "        \"MAE_CV_Std_s\": cv_mae_std,\n",
    "        \"MAE_CV_Mean_m\": cv_mae_mean_m,\n",
    "        \"MAE_CV_Std_m\": cv_mae_std_m,\n",
    "        \"Best_Hyperparameters\": {\n",
    "            \"max_depth\": int(best['max_depth']),\n",
    "            \"learning_rate\": best['learning_rate'],\n",
    "            \"subsample\": best['subsample'],\n",
    "            \"colsample_bytree\": best['colsample_bytree'],\n",
    "            \"n_estimators\": best['n_estimators']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return results_dict, xgb_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model_shap(model: BaseEstimator, X_train: pd.DataFrame, X_test: pd.DataFrame, directory: str):\n",
    "    \"\"\"\n",
    "    Explains a regression model using SHAP and saves the plot.\n",
    "\n",
    "    Parameters:\n",
    "        model (BaseEstimator): The trained regression model.\n",
    "        X_train (pd.DataFrame): The training dataset (features).\n",
    "        X_test (pd.DataFrame): The testing dataset (features).\n",
    "        directory (str): The directory where the plot should be saved.\n",
    "\n",
    "    Returns:\n",
    "        shap.Explainer, Explanation: A tuple containing the SHAP explainer and SHAP values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the model name\n",
    "    model_name = type(model).__name__\n",
    "\n",
    "    # Create a SHAP explainer\n",
    "    explainer = shap.Explainer(model, X_train)\n",
    "\n",
    "    # Compute SHAP values for the test set\n",
    "    shap_values = explainer(X_test)\n",
    "\n",
    "    # Plot the SHAP summary plot\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    shap.summary_plot(shap_values, X_test)\n",
    "    plt_title = f\"SHAP Summary Plot \\n Model: {str(model_name)})\"\n",
    "    plt.title(plt_title)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Create the file path\n",
    "    file_path = Path(directory) / f\"{model_name}_shap.png\"\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(file_path)\n",
    "    print(f\"SHAP summary plot saved as: {file_path}\")\n",
    "\n",
    "    # Close the plot to free up memory\n",
    "    plt.close()\n",
    "\n",
    "    return explainer, shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** PROGRAM START ***\n",
      "\n",
      "Start process: 2024-08-11 12:29:04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### MAIN ###\n",
    "print()\n",
    "print(\"*** PROGRAM START ***\")\n",
    "print()\n",
    "\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Start process:\", str(start_time))\n",
    "print()\n",
    "\n",
    "# print(yaml_config) # debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating output directories\n",
      "Directory 'data_ml' created successfully.\n",
      "Directory 'plots' created successfully.\n",
      "Directory 'shap' created successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\">> Creating output directories\")\n",
    "dir_list = []\n",
    "dir_list.append(Path(ml_dir))\n",
    "dir_list.append(Path(plot_dir))\n",
    "dir_list.append(Path(shap_dir))\n",
    "\n",
    "for dir_name in dir_list:\n",
    "    dir_name.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Directory '{dir_name}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Listing event log prefixes files\n",
      "Files found (num): 18\n",
      "Files found (list): ['EVENT-LOG_ED_duration_enr_prefix_1h_B.csv', 'EVENT-LOG_ED_duration_enr_prefix_1h_F.csv', 'EVENT-LOG_ED_duration_enr_prefix_1h_I.csv', 'EVENT-LOG_ED_duration_enr_prefix_2h_B.csv', 'EVENT-LOG_ED_duration_enr_prefix_2h_F.csv', 'EVENT-LOG_ED_duration_enr_prefix_2h_I.csv', 'EVENT-LOG_ED_duration_enr_prefix_3h_B.csv', 'EVENT-LOG_ED_duration_enr_prefix_3h_F.csv', 'EVENT-LOG_ED_duration_enr_prefix_3h_I.csv', 'EVENT-LOG_ED_duration_std_prefix_1h_B.csv', 'EVENT-LOG_ED_duration_std_prefix_1h_F.csv', 'EVENT-LOG_ED_duration_std_prefix_1h_I.csv', 'EVENT-LOG_ED_duration_std_prefix_2h_B.csv', 'EVENT-LOG_ED_duration_std_prefix_2h_F.csv', 'EVENT-LOG_ED_duration_std_prefix_2h_I.csv', 'EVENT-LOG_ED_duration_std_prefix_3h_B.csv', 'EVENT-LOG_ED_duration_std_prefix_3h_F.csv', 'EVENT-LOG_ED_duration_std_prefix_3h_I.csv']\n",
      "\n",
      "> Splitting standad and enriched\n",
      "Files standard found (num): 9\n",
      "Files standard found (list): ['EVENT-LOG_ED_duration_std_prefix_1h_B.csv', 'EVENT-LOG_ED_duration_std_prefix_1h_F.csv', 'EVENT-LOG_ED_duration_std_prefix_1h_I.csv', 'EVENT-LOG_ED_duration_std_prefix_2h_B.csv', 'EVENT-LOG_ED_duration_std_prefix_2h_F.csv', 'EVENT-LOG_ED_duration_std_prefix_2h_I.csv', 'EVENT-LOG_ED_duration_std_prefix_3h_B.csv', 'EVENT-LOG_ED_duration_std_prefix_3h_F.csv', 'EVENT-LOG_ED_duration_std_prefix_3h_I.csv']\n",
      "Files enriched found (num): 9\n",
      "Files enriched found (list): ['EVENT-LOG_ED_duration_enr_prefix_1h_B.csv', 'EVENT-LOG_ED_duration_enr_prefix_1h_F.csv', 'EVENT-LOG_ED_duration_enr_prefix_1h_I.csv', 'EVENT-LOG_ED_duration_enr_prefix_2h_B.csv', 'EVENT-LOG_ED_duration_enr_prefix_2h_F.csv', 'EVENT-LOG_ED_duration_enr_prefix_2h_I.csv', 'EVENT-LOG_ED_duration_enr_prefix_3h_B.csv', 'EVENT-LOG_ED_duration_enr_prefix_3h_F.csv', 'EVENT-LOG_ED_duration_enr_prefix_3h_I.csv']\n"
     ]
    }
   ],
   "source": [
    "print(\">> Listing event log prefixes files\")\n",
    "list_files = extract_files(encoding_dir, \"csv\")\n",
    "list_files_len = len(list_files)\n",
    "print(\"Files found (num):\", list_files_len)\n",
    "print(\"Files found (list):\", list_files)\n",
    "print()\n",
    "\n",
    "print(\"> Splitting standad and enriched\")\n",
    "\n",
    "list_files_std = [file for file in list_files if f'_{std_suffix}_' in file]\n",
    "list_files_std_len = len(list_files_std)\n",
    "\n",
    "list_files_enr = [file for file in list_files if f'_{enr_suffix}_' in file]\n",
    "list_files_enr_len = len(list_files_enr)\n",
    "\n",
    "print(\"Files standard found (num):\", list_files_std_len)\n",
    "print(\"Files standard found (list):\", list_files_std)\n",
    "print(\"Files enriched found (num):\", list_files_enr_len)\n",
    "print(\"Files enriched found (list):\", list_files_enr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Hypertuning settings\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "print(\">> Hypertuning settings\")\n",
    "ht_str = \"no\" if ht_do == 0 else \"yes\"\n",
    "print(ht_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Reading event log prefixes files and applying ML / DL\n",
      "[1 / 18]\n",
      "File: data_encoding/EVENT-LOG_ED_duration_enr_prefix_1h_B.csv\n",
      "Type (std / enr): enr\n",
      "Prefix length: 1\n",
      "Encoding: B\n",
      "Event log shape: (11289, 195)\n",
      "Event log cases: 3478\n",
      "> Removing columns\n",
      "['CaseID', 'TIMESTAMP']\n",
      "> Preparing data for regression\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Preparing data for regression\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m df_log_ml_features \u001b[38;5;241m=\u001b[39m df_log_ml\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREMAINING_TIME_sec\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Final features as input to the model\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInput features:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m(df_log_ml_features\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Select the \"label\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m target \u001b[38;5;241m=\u001b[39m df_log_ml[label_column]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'len'"
     ]
    }
   ],
   "source": [
    "list_results_ml = []\n",
    "print(\">> Reading event log prefixes files and applying ML / DL\")\n",
    "i = 1\n",
    "for file_name in list_files:\n",
    "    print(f\"[{i} / {list_files_len}]\")\n",
    "    path_data = Path(encoding_dir) / file_name\n",
    "    print(\"File:\", path_data)\n",
    "\n",
    "    # Get from the file_name type, prefix length and encoding type\n",
    "    pattern = r'duration_(enr|std)_prefix_(\\d+)h_([A-Z])' \n",
    "    match = re.search(pattern, file_name)\n",
    "    type = match.group(1)\n",
    "    prefix = match.group(2)\n",
    "    encoding = match.group(3)\n",
    "    print(\"Type (std / enr):\", type )\n",
    "    print(\"Prefix length:\", prefix)\n",
    "    print(\"Encoding:\", encoding)\n",
    "\n",
    "    df_log = pd.read_csv(path_data, sep=\";\", dtype=dic_types)\n",
    "    print(\"Event log shape:\", df_log.shape)\n",
    "    print(\"Event log cases:\", df_log[\"CaseID\"].nunique())\n",
    "    # print(df_log.columns) # debug\n",
    "\n",
    "    print(\"> Removing columns\")\n",
    "    print(drop_column)\n",
    "    df_log_ml = df_log.drop(drop_column, axis=1)\n",
    "\n",
    "    print(\"> Preparing data for regression\")\n",
    "    df_log_ml_features = df_log_ml.drop(columns=['REMAINING_TIME_sec'], axis=1) # Final features as input to the model\n",
    "    print(\"Input features:\", len(df_log_ml_features.columns))\n",
    "    \n",
    "    # Select the \"label\"\n",
    "    target = df_log_ml[label_column]\n",
    "\n",
    "    # Training and Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_log_ml_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    results_dict = None \n",
    "    dtr_regressor = None\n",
    "    rfr_regressor = None\n",
    "    xgb_regressor = None\n",
    "\n",
    "    if dic_task[\"DTR\"] == 1:\n",
    "        results_dict, dtr_regressor = perform_regression_dtr_base(X_train, y_train, X_test, y_test, target, df_log_ml_features, file_name, type, prefix, encoding, 5)\n",
    "        list_results_ml.append(results_dict)\n",
    "    \n",
    "    if dic_task[\"RFR\"] == 1:\n",
    "        if ht_do==1:\n",
    "            results_dict, rfr_regressor = perform_regression_rfr(X_train, y_train, X_test, y_test, target, df_log_ml_features, file_name, type, prefix, encoding, 5)\n",
    "        else:\n",
    "            results_dict, rfr_regressor = perform_regression_rfr_base(X_train, y_train, X_test, y_test, target, df_log_ml_features, file_name, type, prefix, encoding, 5)\n",
    "            if shap_do ==1:\n",
    "                explainer, shap_values = explain_model_shap(rfr_regressor, X_train, X_test, shap_dir)\n",
    "        list_results_ml.append(results_dict)\n",
    "\n",
    "    # Performs the function with hypertuning or the basic function\n",
    "    if dic_task[\"XGR\"] == 1:\n",
    "        if ht_do==1:\n",
    "            results_dict, xgb_regressor = perform_regression_xgr(X_train, y_train, X_test, y_test, target, df_log_ml_features, file_name, type, prefix, encoding, 5)\n",
    "        else:\n",
    "            results_dict, xgb_regressor = perform_regression_xgr_base(X_train, y_train, X_test, y_test, target, df_log_ml_features, file_name, type, prefix, encoding, 5)\n",
    "        list_results_ml.append(results_dict)\n",
    "\n",
    "    if dic_task[\"LSTM\"] == 1:\n",
    "        results_dict, lstm_regressor = perform_regression_lstm_base(X_train, y_train, X_test, y_test, target, df_log_ml_features, file_name, type, prefix, encoding, 5)\n",
    "        list_results_ml.append(results_dict)\n",
    "\n",
    "    i+=1\n",
    "    \n",
    "    print(\"-\"*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating ML results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>File</th>\n",
       "      <th>Type</th>\n",
       "      <th>Prefix (h)</th>\n",
       "      <th>Encoding</th>\n",
       "      <th>RMSE_Before_CV_s</th>\n",
       "      <th>MAE_Before_CV_s</th>\n",
       "      <th>RMSE_CV_scores_s</th>\n",
       "      <th>RMSE_CV_Mean_s</th>\n",
       "      <th>RMSE_CV_Std_s</th>\n",
       "      <th>RMSE_CV_Mean_m</th>\n",
       "      <th>RMSE_CV_Std_m</th>\n",
       "      <th>MAE_CV_Scores_s</th>\n",
       "      <th>MAE_CV_Mean_s</th>\n",
       "      <th>MAE_CV_Std_s</th>\n",
       "      <th>MAE_CV_Mean_m</th>\n",
       "      <th>MAE_CV_Std_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTR</td>\n",
       "      <td>EVENT-LOG_ED_duration_enr_prefix_1h_B.csv</td>\n",
       "      <td>enr</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>778.698959</td>\n",
       "      <td>398.028787</td>\n",
       "      <td>[1732.112341408325, 1877.239703625807, 1714.80...</td>\n",
       "      <td>1946.354439</td>\n",
       "      <td>498.542889</td>\n",
       "      <td>32.439241</td>\n",
       "      <td>8.309048</td>\n",
       "      <td>[827.1896220844405, 840.479111307942, 851.6899...</td>\n",
       "      <td>839.512042</td>\n",
       "      <td>60.285291</td>\n",
       "      <td>13.991867</td>\n",
       "      <td>1.004755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFR</td>\n",
       "      <td>EVENT-LOG_ED_duration_enr_prefix_1h_B.csv</td>\n",
       "      <td>enr</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>602.635069</td>\n",
       "      <td>340.635610</td>\n",
       "      <td>[1386.8673046857398, 941.2619317930513, 1263.5...</td>\n",
       "      <td>1238.245414</td>\n",
       "      <td>199.434704</td>\n",
       "      <td>20.637424</td>\n",
       "      <td>3.323912</td>\n",
       "      <td>[580.6324533563206, 565.2523734184573, 604.567...</td>\n",
       "      <td>598.973791</td>\n",
       "      <td>44.599537</td>\n",
       "      <td>9.982897</td>\n",
       "      <td>0.743326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGR</td>\n",
       "      <td>EVENT-LOG_ED_duration_enr_prefix_1h_B.csv</td>\n",
       "      <td>enr</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>2445.865616</td>\n",
       "      <td>580.257629</td>\n",
       "      <td>[4216.694473408677, 2146.272898429379, 3318.72...</td>\n",
       "      <td>3987.206847</td>\n",
       "      <td>1251.580903</td>\n",
       "      <td>66.453447</td>\n",
       "      <td>20.859682</td>\n",
       "      <td>[1231.80474870093, 801.0571331010655, 1065.839...</td>\n",
       "      <td>1056.374494</td>\n",
       "      <td>161.924595</td>\n",
       "      <td>17.606242</td>\n",
       "      <td>2.698743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>EVENT-LOG_ED_duration_enr_prefix_1h_B.csv</td>\n",
       "      <td>enr</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[60582.69679211984, 60349.46006570517, 64703.6...</td>\n",
       "      <td>63053.752999</td>\n",
       "      <td>2170.727539</td>\n",
       "      <td>1050.895883</td>\n",
       "      <td>36.178792</td>\n",
       "      <td>[27948.144243073104, 26138.60518532205, 27919....</td>\n",
       "      <td>28100.618126</td>\n",
       "      <td>1151.746473</td>\n",
       "      <td>468.343635</td>\n",
       "      <td>19.195775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTR</td>\n",
       "      <td>EVENT-LOG_ED_duration_enr_prefix_1h_F.csv</td>\n",
       "      <td>enr</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>757.536028</td>\n",
       "      <td>386.763065</td>\n",
       "      <td>[1733.7688934026746, 1954.1561573790611, 1729....</td>\n",
       "      <td>1853.760308</td>\n",
       "      <td>228.486204</td>\n",
       "      <td>30.896005</td>\n",
       "      <td>3.808103</td>\n",
       "      <td>[815.1470327723649, 838.7426926483614, 866.285...</td>\n",
       "      <td>825.068488</td>\n",
       "      <td>24.479570</td>\n",
       "      <td>13.751141</td>\n",
       "      <td>0.407993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>EVENT-LOG_ED_duration_std_prefix_3h_F.csv</td>\n",
       "      <td>std</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[68250.63900632698, 62552.398238009504, 63588....</td>\n",
       "      <td>64262.086000</td>\n",
       "      <td>2080.367864</td>\n",
       "      <td>1071.034767</td>\n",
       "      <td>34.672798</td>\n",
       "      <td>[29195.63698406333, 27251.756703993327, 27508....</td>\n",
       "      <td>27750.458889</td>\n",
       "      <td>743.616252</td>\n",
       "      <td>462.507648</td>\n",
       "      <td>12.393604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>RFR</td>\n",
       "      <td>EVENT-LOG_ED_duration_std_prefix_3h_I.csv</td>\n",
       "      <td>std</td>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>1704.916094</td>\n",
       "      <td>864.590599</td>\n",
       "      <td>[2364.734614353978, 2003.3332513352275, 2392.2...</td>\n",
       "      <td>2267.410927</td>\n",
       "      <td>155.942385</td>\n",
       "      <td>37.790182</td>\n",
       "      <td>2.599040</td>\n",
       "      <td>[1289.221023346913, 1177.5140497679486, 1348.0...</td>\n",
       "      <td>1314.568973</td>\n",
       "      <td>83.833305</td>\n",
       "      <td>21.909483</td>\n",
       "      <td>1.397222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>XGR</td>\n",
       "      <td>EVENT-LOG_ED_duration_std_prefix_3h_I.csv</td>\n",
       "      <td>std</td>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>4057.790547</td>\n",
       "      <td>1414.289182</td>\n",
       "      <td>[4271.323581782699, 2314.170610522033, 5206.38...</td>\n",
       "      <td>4549.099351</td>\n",
       "      <td>1335.051447</td>\n",
       "      <td>75.818323</td>\n",
       "      <td>22.250857</td>\n",
       "      <td>[1729.8803858464132, 1271.376737655274, 1778.1...</td>\n",
       "      <td>1709.662505</td>\n",
       "      <td>244.884959</td>\n",
       "      <td>28.494375</td>\n",
       "      <td>4.081416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>DTR</td>\n",
       "      <td>EVENT-LOG_ED_duration_std_prefix_3h_I.csv</td>\n",
       "      <td>std</td>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>2132.653235</td>\n",
       "      <td>953.763240</td>\n",
       "      <td>[2847.6696264204975, 2454.9566637109588, 2913....</td>\n",
       "      <td>2937.674522</td>\n",
       "      <td>407.764412</td>\n",
       "      <td>48.961242</td>\n",
       "      <td>6.796074</td>\n",
       "      <td>[1584.463334377938, 1395.2565026637417, 1675.0...</td>\n",
       "      <td>1614.553147</td>\n",
       "      <td>127.884109</td>\n",
       "      <td>26.909219</td>\n",
       "      <td>2.131402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>EVENT-LOG_ED_duration_std_prefix_3h_I.csv</td>\n",
       "      <td>std</td>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[68248.05648612775, 62554.7883619009, 63587.77...</td>\n",
       "      <td>64261.851081</td>\n",
       "      <td>2079.163546</td>\n",
       "      <td>1071.030851</td>\n",
       "      <td>34.652726</td>\n",
       "      <td>[29186.947749827355, 27249.013150047485, 27500...</td>\n",
       "      <td>27744.308204</td>\n",
       "      <td>742.490312</td>\n",
       "      <td>462.405137</td>\n",
       "      <td>12.374839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model                                       File Type Prefix (h) Encoding  \\\n",
       "0    DTR  EVENT-LOG_ED_duration_enr_prefix_1h_B.csv  enr          1        B   \n",
       "1    RFR  EVENT-LOG_ED_duration_enr_prefix_1h_B.csv  enr          1        B   \n",
       "2    XGR  EVENT-LOG_ED_duration_enr_prefix_1h_B.csv  enr          1        B   \n",
       "3   LSTM  EVENT-LOG_ED_duration_enr_prefix_1h_B.csv  enr          1        B   \n",
       "4    DTR  EVENT-LOG_ED_duration_enr_prefix_1h_F.csv  enr          1        F   \n",
       "..   ...                                        ...  ...        ...      ...   \n",
       "67  LSTM  EVENT-LOG_ED_duration_std_prefix_3h_F.csv  std          3        F   \n",
       "69   RFR  EVENT-LOG_ED_duration_std_prefix_3h_I.csv  std          3        I   \n",
       "70   XGR  EVENT-LOG_ED_duration_std_prefix_3h_I.csv  std          3        I   \n",
       "68   DTR  EVENT-LOG_ED_duration_std_prefix_3h_I.csv  std          3        I   \n",
       "71  LSTM  EVENT-LOG_ED_duration_std_prefix_3h_I.csv  std          3        I   \n",
       "\n",
       "    RMSE_Before_CV_s  MAE_Before_CV_s  \\\n",
       "0         778.698959       398.028787   \n",
       "1         602.635069       340.635610   \n",
       "2        2445.865616       580.257629   \n",
       "3                NaN              NaN   \n",
       "4         757.536028       386.763065   \n",
       "..               ...              ...   \n",
       "67               NaN              NaN   \n",
       "69       1704.916094       864.590599   \n",
       "70       4057.790547      1414.289182   \n",
       "68       2132.653235       953.763240   \n",
       "71               NaN              NaN   \n",
       "\n",
       "                                     RMSE_CV_scores_s  RMSE_CV_Mean_s  \\\n",
       "0   [1732.112341408325, 1877.239703625807, 1714.80...     1946.354439   \n",
       "1   [1386.8673046857398, 941.2619317930513, 1263.5...     1238.245414   \n",
       "2   [4216.694473408677, 2146.272898429379, 3318.72...     3987.206847   \n",
       "3   [60582.69679211984, 60349.46006570517, 64703.6...    63053.752999   \n",
       "4   [1733.7688934026746, 1954.1561573790611, 1729....     1853.760308   \n",
       "..                                                ...             ...   \n",
       "67  [68250.63900632698, 62552.398238009504, 63588....    64262.086000   \n",
       "69  [2364.734614353978, 2003.3332513352275, 2392.2...     2267.410927   \n",
       "70  [4271.323581782699, 2314.170610522033, 5206.38...     4549.099351   \n",
       "68  [2847.6696264204975, 2454.9566637109588, 2913....     2937.674522   \n",
       "71  [68248.05648612775, 62554.7883619009, 63587.77...    64261.851081   \n",
       "\n",
       "    RMSE_CV_Std_s  RMSE_CV_Mean_m  RMSE_CV_Std_m  \\\n",
       "0      498.542889       32.439241       8.309048   \n",
       "1      199.434704       20.637424       3.323912   \n",
       "2     1251.580903       66.453447      20.859682   \n",
       "3     2170.727539     1050.895883      36.178792   \n",
       "4      228.486204       30.896005       3.808103   \n",
       "..            ...             ...            ...   \n",
       "67    2080.367864     1071.034767      34.672798   \n",
       "69     155.942385       37.790182       2.599040   \n",
       "70    1335.051447       75.818323      22.250857   \n",
       "68     407.764412       48.961242       6.796074   \n",
       "71    2079.163546     1071.030851      34.652726   \n",
       "\n",
       "                                      MAE_CV_Scores_s  MAE_CV_Mean_s  \\\n",
       "0   [827.1896220844405, 840.479111307942, 851.6899...     839.512042   \n",
       "1   [580.6324533563206, 565.2523734184573, 604.567...     598.973791   \n",
       "2   [1231.80474870093, 801.0571331010655, 1065.839...    1056.374494   \n",
       "3   [27948.144243073104, 26138.60518532205, 27919....   28100.618126   \n",
       "4   [815.1470327723649, 838.7426926483614, 866.285...     825.068488   \n",
       "..                                                ...            ...   \n",
       "67  [29195.63698406333, 27251.756703993327, 27508....   27750.458889   \n",
       "69  [1289.221023346913, 1177.5140497679486, 1348.0...    1314.568973   \n",
       "70  [1729.8803858464132, 1271.376737655274, 1778.1...    1709.662505   \n",
       "68  [1584.463334377938, 1395.2565026637417, 1675.0...    1614.553147   \n",
       "71  [29186.947749827355, 27249.013150047485, 27500...   27744.308204   \n",
       "\n",
       "    MAE_CV_Std_s  MAE_CV_Mean_m  MAE_CV_Std_m  \n",
       "0      60.285291      13.991867      1.004755  \n",
       "1      44.599537       9.982897      0.743326  \n",
       "2     161.924595      17.606242      2.698743  \n",
       "3    1151.746473     468.343635     19.195775  \n",
       "4      24.479570      13.751141      0.407993  \n",
       "..           ...            ...           ...  \n",
       "67    743.616252     462.507648     12.393604  \n",
       "69     83.833305      21.909483      1.397222  \n",
       "70    244.884959      28.494375      4.081416  \n",
       "68    127.884109      26.909219      2.131402  \n",
       "71    742.490312     462.405137     12.374839  \n",
       "\n",
       "[72 rows x 17 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\">> Creating ML results\")\n",
    "df_ml = pd.DataFrame.from_records(list_results_ml)\n",
    "df_ml = df_ml.sort_values(by = [\"File\"])\n",
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> Splitting the results by model and event log type\")\n",
    "list_models = sorted(df_ml[\"Model\"].unique().tolist())\n",
    "list_types = sorted(df_ml[\"Type\"].unique().tolist())\n",
    "print(\"Available models:\", list_models)\n",
    "print(\"Available types:\", list_types)\n",
    "for model_name in list_models:\n",
    "    df_ml_model = df_ml[df_ml[\"Model\"] == model_name]\n",
    "    for type_name in list_types:\n",
    "        df_ml_model_type = df_ml_model[df_ml_model[\"Type\"] == type_name]\n",
    "        plot_custom_distribution_side_by_side(df_ml_model_type, \"Prefix (h)\", \"RMSE_CV_Mean_m\", \"Encoding\", f\"{model_name} ({type_name})\", ht_str)\n",
    "        plot_custom_distribution_side_by_side(df_ml_model_type, \"Prefix (h)\", \"MAE_CV_Mean_m\", \"Encoding\", f\"{model_name} ({type_name})\", ht_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Saving ML results for standard event log\n",
      "File: data_ml/ML_results_no_HT.csv\n",
      "File: data_ml/ML_results_no_HT.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(\">> Saving ML results for standard event log\")\n",
    "\n",
    "path_out = Path(ml_dir) / f\"ML_results_{ht_str}_HT.csv\"\n",
    "print(\"File:\", path_out)\n",
    "df_ml.to_csv(path_out, sep=\";\", index=False)\n",
    "\n",
    "path_out = Path(ml_dir) / f\"ML_results_{ht_str}_HT.xlsx\"\n",
    "print(\"File:\", path_out)\n",
    "df_ml.to_excel(path_out, index=False, sheet_name=f\"ML_results_{ht_str}_HT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End process: 2024-08-07 22:39:16\n",
      "Time to finish: 2:42:06\n",
      "\n",
      "*** PROGRAM END ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# program end\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "delta_time = end_time - start_time\n",
    "\n",
    "print(\"End process:\", end_time)\n",
    "print(\"Time to finish:\", delta_time)\n",
    "\n",
    "print()\n",
    "print(\"*** PROGRAM END ***\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
